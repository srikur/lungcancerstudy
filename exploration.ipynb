{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "# import selenium exceptions\n",
    "from selenium.common.exceptions import *\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "ctg_studies = pd.read_csv('ctg-studies.csv')\n",
    "# Zip together 'NCT Number' and \"Study URL\"\n",
    "studies = list(zip(ctg_studies['NCT Number'], ctg_studies['Study URL']))\n",
    "\n",
    "options = Options()\n",
    "# options.add_argument('--headless')\n",
    "options.add_argument('--window-size=1920x1080')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "unscraped_links = []\n",
    "df = pd.DataFrame(columns=['NCT Number', 'Study URL', 'Table'])\n",
    "\n",
    "@dataclass\n",
    "class Study:\n",
    "    nct: str\n",
    "    link: str\n",
    "    table: str\n",
    "\n",
    "studies_dc = []\n",
    "# Create an empty file 'studies_scraped_tables.csv' to store the scraped tables if it doesn't exist\n",
    "if not os.path.exists('studies_scraped_tables.csv'):\n",
    "    with open('studies_scraped_tables.csv', 'w') as f:\n",
    "        f.write('NCT Number,Study URL,Table\\n')\n",
    "\n",
    "for nct, link in studies[:1]:\n",
    "    # 1. Use Selenium to open the link\n",
    "    # 2. Click on the \"Results Posted\" tab\n",
    "    # 3. Click on the \"Expand all\" button with the attribute data-ga-category=\"Baseline Characteristics\"\n",
    "    # 4. Extract the first instance of a <table> tag that is a child of a <ctg-sticky-container> tag\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        # Wait until the \"Results Posted\" tab is clickable\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            lambda driver: driver.find_element(By.XPATH, \"//*[contains(text(), 'Results Posted')]\").is_displayed()\n",
    "        )\n",
    "        driver.find_element(By.XPATH, \"//*[contains(text(), 'Results Posted')]\").click()\n",
    "        print('Found Results Posted tab')\n",
    "        # Wait until the \"Expand all\" button is clickable. Use XPATH to find the button by its data-ga-category attribute\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            lambda driver: driver.find_element(By.XPATH, \"//button[@data-ga-action='Baseline Characteristics']\")\n",
    "        )\n",
    "        print('Found Results Posted tab and Expand all button')\n",
    "        driver.find_element(By.XPATH, \"//button[@data-ga-action='Baseline Characteristics']\").click()\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        table = soup.select_one('ctg-baseline-characteristics').select_one('table').prettify()\n",
    "        if table:\n",
    "            # Store in a dataframe with columns \"NCT Number\", \"Study URL\", and \"Table\"\n",
    "            # First store in dataclass\n",
    "            study = Study(nct, link, table)\n",
    "            studies_dc.append(study)\n",
    "            # write to csv\n",
    "            with open('studies_scraped_tables.csv', 'a') as f:\n",
    "                f.write(f'{study.nct},{study.link},{study.table}\\n')\n",
    "        else:\n",
    "            print('No table found for', link)\n",
    "            unscraped_links.append(link)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table _ngcontent-ng-c4179008994=\"\" style=\"width: max(417px, 100%);\">\\n <colgroup _ngcontent-ng-c4179008994=\"\">\\n  <col _ngcontent-ng-c4179008994=\"\" style=\"width: 162px;\"/>\\n  <col _ngcontent-ng-c4179008994=\"\" style=\"width: 1fr;\"/>\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n </colgroup>\\n <!-- -->\\n <thead _ngcontent-ng-c4179008994=\"\">\\n  <tr _ngcontent-ng-c4179008994=\"\" class=\"sticky-head\">\\n   <th _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n    Arm/Group Title\\n   </th>\\n   <th _ngcontent-ng-c4179008994=\"\" colspan=\"1\">\\n    Afatinib 50mg\\n   </th>\\n   <!-- -->\\n  </tr>\\n  <tr _ngcontent-ng-c4179008994=\"\">\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n    Arm/Group Description\\n   </td>\\n   <td _ngcontent-ng-c4179008994=\"\" colspan=\"1\">\\n    <!-- -->\\n    <div _ngcontent-ng-c4179008994=\"\" class=\"rel\">\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"markup-collapsed\" id=\"baseline-0-0\">\\n      <span _ngcontent-ng-c4179008994=\"\">\\n       Afatinib 50mg film coated tablets were administered once daily as long as they were tolerated by patients, until disease progression (according to the response evaluation criteria in solid tumors)\\n      </span>\\n      <!-- -->\\n      <!-- -->\\n     </div>\\n    </div>\\n    <a _ngcontent-ng-c4179008994=\"\" class=\"more-markup usa-link\" href=\"javascript:void(0)\" style=\"display: none;\">\\n     <svg _ngcontent-ng-c4179008994=\"\" aria-hidden=\"true\" class=\"usa-icon\" focusable=\"false\" role=\"img\">\\n      <use _ngcontent-ng-c4179008994=\"\" xlink:href=\"/assets/uswds/img/sprite.svg#add\">\\n      </use>\\n     </svg>\\n     Show more\\n    </a>\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <!-- -->\\n  </tr>\\n  <!-- -->\\n  <!-- -->\\n  <tr _ngcontent-ng-c4179008994=\"\">\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n    <span _ngcontent-ng-c4179008994=\"\">\\n     Overall Number of Baseline Participants\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"data-cell\" colspan=\"0\">\\n    <span _ngcontent-ng-c4179008994=\"\" class=\"cell-value\">\\n     41\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <!-- -->\\n  </tr>\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <tr _ngcontent-ng-c4179008994=\"\">\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n    <div _ngcontent-ng-c4179008994=\"\" class=\"rel\">\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"single-cell-body\" style=\"left: 162px; width: min(825px, 100vw - 632px);\">\\n      <span _ngcontent-ng-c4179008994=\"\" class=\"cell-value\">\\n       [Not Specified]\\n      </span>\\n     </div>\\n    </div>\\n    <span _ngcontent-ng-c4179008994=\"\">\\n     Baseline Analysis Population Description\\n    </span>\\n   </td>\\n   <td _ngcontent-ng-c4179008994=\"\" colspan=\"1\">\\n    <div _ngcontent-ng-c4179008994=\"\" class=\"single-cell-spacer\" style=\"left: 162px; width: min(825px, 100vw - 632px);\">\\n     <span _ngcontent-ng-c4179008994=\"\" class=\"cell-value\">\\n      [Not Specified]\\n     </span>\\n    </div>\\n   </td>\\n  </tr>\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n </thead>\\n <tr _ngcontent-ng-c4179008994=\"\" class=\"exp-all\">\\n  <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n   <div _ngcontent-ng-c4179008994=\"\" class=\"rel\">\\n    <div _ngcontent-ng-c4179008994=\"\" class=\"exp-all-body\" style=\"width: 805px;\">\\n     <button _ngcontent-ng-c4179008994=\"\" class=\"usa-button usa-button--unstyled\" data-ga-action=\"Baseline Characteristics\" data-ga-category=\"Study Results\" data-ga-label=\"Expand all\" style=\"width: auto;\">\\n      Expand all\\n     </button>\\n     /\\n     <button _ngcontent-ng-c4179008994=\"\" class=\"usa-button usa-button--unstyled\" data-ga-action=\"Baseline Characteristics\" data-ga-category=\"Study Results\" data-ga-label=\"Collapse all\" style=\"width: auto;\">\\n      Collapse all\\n     </button>\\n    </div>\\n   </div>\\n  </td>\\n  <td _ngcontent-ng-c4179008994=\"\">\\n  </td>\\n  <!-- -->\\n </tr>\\n <!-- -->\\n <tr _ngcontent-ng-c4179008994=\"\" class=\"sticky-group\">\\n  <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\" style=\"height: 96px;\">\\n   <div _ngcontent-ng-c4179008994=\"\" class=\"rel\">\\n    <a _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-panel sticky-group-panel__expanded\" href=\"#\" style=\"width: 805px;\">\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-panel-body\">\\n      <div _ngcontent-ng-c4179008994=\"\" class=\"group-title\">\\n       <!-- -->\\n       <span _ngcontent-ng-c4179008994=\"\" class=\"group-title-text\">\\n        Age, Continuous\\n       </span>\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n      </div>\\n      <!-- -->\\n      <div _ngcontent-ng-c4179008994=\"\" class=\"group-description\">\\n       <span _ngcontent-ng-c4179008994=\"\">\\n        Mean (Standard Deviation)\\n       </span>\\n       |\\n       <!-- -->\\n       <span _ngcontent-ng-c4179008994=\"\">\\n        Unit of measure: years\\n       </span>\\n       <!-- -->\\n       <!-- -->\\n      </div>\\n      <!-- -->\\n      <!-- -->\\n     </div>\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-panel-toggle\">\\n      <svg _ngcontent-ng-c4179008994=\"\" aria-hidden=\"true\" class=\"usa-icon expand_less\" focusable=\"false\" role=\"img\">\\n       <use _ngcontent-ng-c4179008994=\"\" xlink:href=\"/assets/uswds/img/sprite.svg#remove\">\\n       </use>\\n      </svg>\\n      <!-- -->\\n      <!-- -->\\n     </div>\\n    </a>\\n    <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-spacer\" style=\"width: 805px;\">\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-spacer-body\">\\n      <div _ngcontent-ng-c4179008994=\"\" class=\"group-title\">\\n       <!-- -->\\n       <span _ngcontent-ng-c4179008994=\"\" class=\"group-title-text\">\\n        Age, Continuous\\n       </span>\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n      </div>\\n      <!-- -->\\n      <div _ngcontent-ng-c4179008994=\"\" class=\"group-description\">\\n       <span _ngcontent-ng-c4179008994=\"\">\\n        Mean (Standard Deviation)\\n       </span>\\n       |\\n       <!-- -->\\n       <span _ngcontent-ng-c4179008994=\"\">\\n        Unit of measure: years\\n       </span>\\n       <!-- -->\\n       <!-- -->\\n      </div>\\n      <!-- -->\\n      <!-- -->\\n     </div>\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-spacer-toggle\">\\n      <svg _ngcontent-ng-c4179008994=\"\" aria-hidden=\"true\" class=\"usa-icon expand_less\" focusable=\"false\" role=\"img\">\\n       <use _ngcontent-ng-c4179008994=\"\" xlink:href=\"/assets/uswds/img/sprite.svg#remove\">\\n       </use>\\n      </svg>\\n      <!-- -->\\n      <!-- -->\\n     </div>\\n    </div>\\n   </div>\\n  </td>\\n  <td _ngcontent-ng-c4179008994=\"\">\\n  </td>\\n  <!-- -->\\n </tr>\\n <!-- -->\\n <tbody _ngcontent-ng-c4179008994=\"\">\\n  <!-- -->\\n  <!-- -->\\n  <tr _ngcontent-ng-c4179008994=\"\">\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n    <span _ngcontent-ng-c4179008994=\"\">\\n     Number Analyzed\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"data-cell\" colspan=\"0\">\\n    <span _ngcontent-ng-c4179008994=\"\" class=\"cell-value\">\\n     41 participants\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <!-- -->\\n  </tr>\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <tr _ngcontent-ng-c4179008994=\"\">\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n    <span _ngcontent-ng-c4179008994=\"\">\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"data-cell\" colspan=\"0\">\\n    <span _ngcontent-ng-c4179008994=\"\" class=\"cell-value\">\\n     60.7\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <span _ngcontent-ng-c4179008994=\"\" class=\"cell-spread\">\\n     (13.4)\\n    </span>\\n    <!-- -->\\n   </td>\\n   <!-- -->\\n  </tr>\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n </tbody>\\n <!-- -->\\n <!-- -->\\n <tr _ngcontent-ng-c4179008994=\"\" class=\"sticky-group\">\\n  <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\" style=\"height: 96px;\">\\n   <div _ngcontent-ng-c4179008994=\"\" class=\"rel\">\\n    <a _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-panel sticky-group-panel__expanded\" href=\"#\" style=\"width: 805px;\">\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-panel-body\">\\n      <div _ngcontent-ng-c4179008994=\"\" class=\"group-title\">\\n       <!-- -->\\n       <span _ngcontent-ng-c4179008994=\"\" class=\"group-title-text\">\\n        Sex: Female, Male\\n       </span>\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n      </div>\\n      <!-- -->\\n      <div _ngcontent-ng-c4179008994=\"\" class=\"group-description\">\\n       <span _ngcontent-ng-c4179008994=\"\">\\n        Measure Type: Count of Participants\\n       </span>\\n       |\\n       <!-- -->\\n       <span _ngcontent-ng-c4179008994=\"\">\\n        Unit of measure: Participants\\n       </span>\\n       <!-- -->\\n       <!-- -->\\n      </div>\\n      <!-- -->\\n      <!-- -->\\n     </div>\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-panel-toggle\">\\n      <svg _ngcontent-ng-c4179008994=\"\" aria-hidden=\"true\" class=\"usa-icon expand_less\" focusable=\"false\" role=\"img\">\\n       <use _ngcontent-ng-c4179008994=\"\" xlink:href=\"/assets/uswds/img/sprite.svg#remove\">\\n       </use>\\n      </svg>\\n      <!-- -->\\n      <!-- -->\\n     </div>\\n    </a>\\n    <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-spacer\" style=\"width: 805px;\">\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-spacer-body\">\\n      <div _ngcontent-ng-c4179008994=\"\" class=\"group-title\">\\n       <!-- -->\\n       <span _ngcontent-ng-c4179008994=\"\" class=\"group-title-text\">\\n        Sex: Female, Male\\n       </span>\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n       <!-- -->\\n      </div>\\n      <!-- -->\\n      <div _ngcontent-ng-c4179008994=\"\" class=\"group-description\">\\n       <span _ngcontent-ng-c4179008994=\"\">\\n        Measure Type: Count of Participants\\n       </span>\\n       |\\n       <!-- -->\\n       <span _ngcontent-ng-c4179008994=\"\">\\n        Unit of measure: Participants\\n       </span>\\n       <!-- -->\\n       <!-- -->\\n      </div>\\n      <!-- -->\\n      <!-- -->\\n     </div>\\n     <div _ngcontent-ng-c4179008994=\"\" class=\"sticky-group-spacer-toggle\">\\n      <svg _ngcontent-ng-c4179008994=\"\" aria-hidden=\"true\" class=\"usa-icon expand_less\" focusable=\"false\" role=\"img\">\\n       <use _ngcontent-ng-c4179008994=\"\" xlink:href=\"/assets/uswds/img/sprite.svg#remove\">\\n       </use>\\n      </svg>\\n      <!-- -->\\n      <!-- -->\\n     </div>\\n    </div>\\n   </div>\\n  </td>\\n  <td _ngcontent-ng-c4179008994=\"\">\\n  </td>\\n  <!-- -->\\n </tr>\\n <!-- -->\\n <tbody _ngcontent-ng-c4179008994=\"\">\\n  <!-- -->\\n  <!-- -->\\n  <tr _ngcontent-ng-c4179008994=\"\">\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n    <span _ngcontent-ng-c4179008994=\"\">\\n     Number Analyzed\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"data-cell\" colspan=\"0\">\\n    <span _ngcontent-ng-c4179008994=\"\" class=\"cell-value\">\\n     41 participants\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <!-- -->\\n  </tr>\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <tr _ngcontent-ng-c4179008994=\"\">\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n    <span _ngcontent-ng-c4179008994=\"\">\\n     Female\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"data-cell data-cell__percented\" colspan=\"0\">\\n    <span _ngcontent-ng-c4179008994=\"\" class=\"cell-value\">\\n     26\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <span _ngcontent-ng-c4179008994=\"\" class=\"cell-percentage\">\\n     63.4%\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <!-- -->\\n  </tr>\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <tr _ngcontent-ng-c4179008994=\"\">\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"sticky-col\">\\n    <span _ngcontent-ng-c4179008994=\"\">\\n     Male\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <td _ngcontent-ng-c4179008994=\"\" class=\"data-cell data-cell__percented\" colspan=\"0\">\\n    <span _ngcontent-ng-c4179008994=\"\" class=\"cell-value\">\\n     15\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <!-- -->\\n    <span _ngcontent-ng-c4179008994=\"\" class=\"cell-percentage\">\\n     36.6%\\n    </span>\\n    <!-- -->\\n    <!-- -->\\n   </td>\\n   <!-- -->\\n  </tr>\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n  <!-- -->\\n </tbody>\\n <!-- -->\\n <!-- -->\\n <!-- -->\\n <!-- -->\\n <!-- -->\\n</table>\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_table = BeautifulSoup(studies_dc[0].table, \"html.parser\").prettify()\n",
    "# Remove all of the text in between a < and > for each tag, except for the tag type\n",
    "def remove_text_between_tags(table_str: str):\n",
    "    \"\"\"\n",
    "    Removes all of the text in between a < and > for each tag, except for the tag type\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove all of the text in between a < and > for each tag, except for the tag type\n",
    "    new_table = ''\n",
    "    index = 0\n",
    "    while index < len(table_str):\n",
    "        if table_str[index] == '<':\n",
    "            new_table += table_str[index]\n",
    "            index += 1\n",
    "            # add characters until the next space is found\n",
    "            while (table_str[index] != ' ') and (table_str[index] != '>'):\n",
    "                new_table += table_str[index]\n",
    "                index += 1\n",
    "            while table_str[index] != '>':\n",
    "                index += 1\n",
    "        else:\n",
    "            new_table += table_str[index]\n",
    "        index += 1\n",
    "    \n",
    "    # Remove all \\n and spaces from string\n",
    "    new_table = new_table.replace('\\n', '')\n",
    "    new_table = new_table.replace(' ', '')\n",
    "    new_table = new_table.replace('<!--', '')\n",
    "    return new_table\n",
    "\n",
    "table_str = remove_text_between_tags(soup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1745"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_studies = pd.read_csv('ctg-studies.csv')\n",
    "# Zip together 'NCT Number' and \"Study URL\"\n",
    "studies = list(zip(ctg_studies['NCT Number'], ctg_studies['Study URL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NCT00520676', 'https://clinicaltrials.gov/study/NCT00520676'),\n",
       " ('NCT00979576', 'https://clinicaltrials.gov/study/NCT00979576'),\n",
       " ('NCT02856581', 'https://clinicaltrials.gov/study/NCT02856581'),\n",
       " ('NCT00406276', 'https://clinicaltrials.gov/study/NCT00406276'),\n",
       " ('NCT03041181', 'https://clinicaltrials.gov/study/NCT03041181'),\n",
       " ('NCT02151981', 'https://clinicaltrials.gov/study/NCT02151981'),\n",
       " ('NCT00993499', 'https://clinicaltrials.gov/study/NCT00993499'),\n",
       " ('NCT00538681', 'https://clinicaltrials.gov/study/NCT00538681'),\n",
       " ('NCT03043599', 'https://clinicaltrials.gov/study/NCT03043599'),\n",
       " ('NCT00391274', 'https://clinicaltrials.gov/study/NCT00391274'),\n",
       " ('NCT01049776', 'https://clinicaltrials.gov/study/NCT01049776'),\n",
       " ('NCT02367781', 'https://clinicaltrials.gov/study/NCT02367781'),\n",
       " ('NCT00632281', 'https://clinicaltrials.gov/study/NCT00632281'),\n",
       " ('NCT01750281', 'https://clinicaltrials.gov/study/NCT01750281'),\n",
       " ('NCT03382899', 'https://clinicaltrials.gov/study/NCT03382899'),\n",
       " ('NCT01260181', 'https://clinicaltrials.gov/study/NCT01260181'),\n",
       " ('NCT01533181', 'https://clinicaltrials.gov/study/NCT01533181'),\n",
       " ('NCT01511081', 'https://clinicaltrials.gov/study/NCT01511081'),\n",
       " ('NCT01657799', 'https://clinicaltrials.gov/study/NCT01657799'),\n",
       " ('NCT00765570', 'https://clinicaltrials.gov/study/NCT00765570'),\n",
       " ('NCT03370770', 'https://clinicaltrials.gov/study/NCT03370770'),\n",
       " ('NCT02085070', 'https://clinicaltrials.gov/study/NCT02085070'),\n",
       " ('NCT04398199', 'https://clinicaltrials.gov/study/NCT04398199'),\n",
       " ('NCT02040870', 'https://clinicaltrials.gov/study/NCT02040870'),\n",
       " ('NCT02087176', 'https://clinicaltrials.gov/study/NCT02087176'),\n",
       " ('NCT03033511', 'https://clinicaltrials.gov/study/NCT03033511'),\n",
       " ('NCT00960999', 'https://clinicaltrials.gov/study/NCT00960999'),\n",
       " ('NCT00095199', 'https://clinicaltrials.gov/study/NCT00095199'),\n",
       " ('NCT00475657', 'https://clinicaltrials.gov/study/NCT00475657'),\n",
       " ('NCT01557881', 'https://clinicaltrials.gov/study/NCT01557881'),\n",
       " ('NCT00126581', 'https://clinicaltrials.gov/study/NCT00126581'),\n",
       " ('NCT00918281', 'https://clinicaltrials.gov/study/NCT00918281'),\n",
       " ('NCT04590781', 'https://clinicaltrials.gov/study/NCT04590781'),\n",
       " ('NCT02403895', 'https://clinicaltrials.gov/study/NCT02403895'),\n",
       " ('NCT01077713', 'https://clinicaltrials.gov/study/NCT01077713'),\n",
       " ('NCT00551369', 'https://clinicaltrials.gov/study/NCT00551369'),\n",
       " ('NCT00487669', 'https://clinicaltrials.gov/study/NCT00487669'),\n",
       " ('NCT01387269', 'https://clinicaltrials.gov/study/NCT01387269'),\n",
       " ('NCT01189435', 'https://clinicaltrials.gov/study/NCT01189435'),\n",
       " ('NCT00408499', 'https://clinicaltrials.gov/study/NCT00408499'),\n",
       " ('NCT00495170', 'https://clinicaltrials.gov/study/NCT00495170'),\n",
       " ('NCT00963911', 'https://clinicaltrials.gov/study/NCT00963911'),\n",
       " ('NCT02899299', 'https://clinicaltrials.gov/study/NCT02899299'),\n",
       " ('NCT01647711', 'https://clinicaltrials.gov/study/NCT01647711'),\n",
       " ('NCT00982111', 'https://clinicaltrials.gov/study/NCT00982111'),\n",
       " ('NCT02346370', 'https://clinicaltrials.gov/study/NCT02346370'),\n",
       " ('NCT00084799', 'https://clinicaltrials.gov/study/NCT00084799'),\n",
       " ('NCT01828099', 'https://clinicaltrials.gov/study/NCT01828099'),\n",
       " ('NCT02499770', 'https://clinicaltrials.gov/study/NCT02499770'),\n",
       " ('NCT00518011', 'https://clinicaltrials.gov/study/NCT00518011'),\n",
       " ('NCT00129974', 'https://clinicaltrials.gov/study/NCT00129974'),\n",
       " ('NCT02514174', 'https://clinicaltrials.gov/study/NCT02514174'),\n",
       " ('NCT02862457', 'https://clinicaltrials.gov/study/NCT02862457'),\n",
       " ('NCT03233724', 'https://clinicaltrials.gov/study/NCT03233724'),\n",
       " ('NCT01905657', 'https://clinicaltrials.gov/study/NCT01905657'),\n",
       " ('NCT04161157', 'https://clinicaltrials.gov/study/NCT04161157'),\n",
       " ('NCT00789373', 'https://clinicaltrials.gov/study/NCT00789373'),\n",
       " ('NCT01752023', 'https://clinicaltrials.gov/study/NCT01752023'),\n",
       " ('NCT01218594', 'https://clinicaltrials.gov/study/NCT01218594'),\n",
       " ('NCT01982123', 'https://clinicaltrials.gov/study/NCT01982123'),\n",
       " ('NCT00994123', 'https://clinicaltrials.gov/study/NCT00994123'),\n",
       " ('NCT00376623', 'https://clinicaltrials.gov/study/NCT00376623'),\n",
       " ('NCT01963923', 'https://clinicaltrials.gov/study/NCT01963923'),\n",
       " ('NCT00312728', 'https://clinicaltrials.gov/study/NCT00312728'),\n",
       " ('NCT01404260', 'https://clinicaltrials.gov/study/NCT01404260'),\n",
       " ('NCT03076164', 'https://clinicaltrials.gov/study/NCT03076164'),\n",
       " ('NCT03713944', 'https://clinicaltrials.gov/study/NCT03713944'),\n",
       " ('NCT01026844', 'https://clinicaltrials.gov/study/NCT01026844'),\n",
       " ('NCT00580398', 'https://clinicaltrials.gov/study/NCT00580398'),\n",
       " ('NCT03515629', 'https://clinicaltrials.gov/study/NCT03515629'),\n",
       " ('NCT00496860', 'https://clinicaltrials.gov/study/NCT00496860'),\n",
       " ('NCT01802632', 'https://clinicaltrials.gov/study/NCT01802632'),\n",
       " ('NCT02320123', 'https://clinicaltrials.gov/study/NCT02320123'),\n",
       " ('NCT01967823', 'https://clinicaltrials.gov/study/NCT01967823'),\n",
       " ('NCT02936323', 'https://clinicaltrials.gov/study/NCT02936323'),\n",
       " ('NCT00454324', 'https://clinicaltrials.gov/study/NCT00454324'),\n",
       " ('NCT01281124', 'https://clinicaltrials.gov/study/NCT01281124'),\n",
       " ('NCT01586624', 'https://clinicaltrials.gov/study/NCT01586624'),\n",
       " ('NCT01662635', 'https://clinicaltrials.gov/study/NCT01662635'),\n",
       " ('NCT00859469', 'https://clinicaltrials.gov/study/NCT00859469'),\n",
       " ('NCT03220035', 'https://clinicaltrials.gov/study/NCT03220035'),\n",
       " ('NCT00101413', 'https://clinicaltrials.gov/study/NCT00101413'),\n",
       " ('NCT04373369', 'https://clinicaltrials.gov/study/NCT04373369'),\n",
       " ('NCT01228435', 'https://clinicaltrials.gov/study/NCT01228435'),\n",
       " ('NCT00122135', 'https://clinicaltrials.gov/study/NCT00122135'),\n",
       " ('NCT00988169', 'https://clinicaltrials.gov/study/NCT00988169'),\n",
       " ('NCT03041311', 'https://clinicaltrials.gov/study/NCT03041311'),\n",
       " ('NCT00497770', 'https://clinicaltrials.gov/study/NCT00497770'),\n",
       " ('NCT00999713', 'https://clinicaltrials.gov/study/NCT00999713'),\n",
       " ('NCT00326599', 'https://clinicaltrials.gov/study/NCT00326599'),\n",
       " ('NCT02007070', 'https://clinicaltrials.gov/study/NCT02007070'),\n",
       " ('NCT02364999', 'https://clinicaltrials.gov/study/NCT02364999'),\n",
       " ('NCT00870870', 'https://clinicaltrials.gov/study/NCT00870870'),\n",
       " ('NCT01342770', 'https://clinicaltrials.gov/study/NCT01342770'),\n",
       " ('NCT00977470', 'https://clinicaltrials.gov/study/NCT00977470'),\n",
       " ('NCT01178411', 'https://clinicaltrials.gov/study/NCT01178411'),\n",
       " ('NCT03569111', 'https://clinicaltrials.gov/study/NCT03569111'),\n",
       " ('NCT02272413', 'https://clinicaltrials.gov/study/NCT02272413'),\n",
       " ('NCT01652469', 'https://clinicaltrials.gov/study/NCT01652469'),\n",
       " ('NCT01380769', 'https://clinicaltrials.gov/study/NCT01380769'),\n",
       " ('NCT00888511', 'https://clinicaltrials.gov/study/NCT00888511'),\n",
       " ('NCT01090011', 'https://clinicaltrials.gov/study/NCT01090011'),\n",
       " ('NCT00662311', 'https://clinicaltrials.gov/study/NCT00662311'),\n",
       " ('NCT02785913', 'https://clinicaltrials.gov/study/NCT02785913'),\n",
       " ('NCT01658813', 'https://clinicaltrials.gov/study/NCT01658813'),\n",
       " ('NCT00537511', 'https://clinicaltrials.gov/study/NCT00537511'),\n",
       " ('NCT03329911', 'https://clinicaltrials.gov/study/NCT03329911'),\n",
       " ('NCT01253369', 'https://clinicaltrials.gov/study/NCT01253369'),\n",
       " ('NCT00452413', 'https://clinicaltrials.gov/study/NCT00452413'),\n",
       " ('NCT02286713', 'https://clinicaltrials.gov/study/NCT02286713'),\n",
       " ('NCT01217411', 'https://clinicaltrials.gov/study/NCT01217411'),\n",
       " ('NCT01953913', 'https://clinicaltrials.gov/study/NCT01953913'),\n",
       " ('NCT02585713', 'https://clinicaltrials.gov/study/NCT02585713'),\n",
       " ('NCT00003869', 'https://clinicaltrials.gov/study/NCT00003869'),\n",
       " ('NCT02133235', 'https://clinicaltrials.gov/study/NCT02133235'),\n",
       " ('NCT00790569', 'https://clinicaltrials.gov/study/NCT00790569'),\n",
       " ('NCT01803269', 'https://clinicaltrials.gov/study/NCT01803269'),\n",
       " ('NCT02759835', 'https://clinicaltrials.gov/study/NCT02759835'),\n",
       " ('NCT04552535', 'https://clinicaltrials.gov/study/NCT04552535'),\n",
       " ('NCT01801111', 'https://clinicaltrials.gov/study/NCT01801111'),\n",
       " ('NCT01829113', 'https://clinicaltrials.gov/study/NCT01829113'),\n",
       " ('NCT00581113', 'https://clinicaltrials.gov/study/NCT00581113'),\n",
       " ('NCT03086213', 'https://clinicaltrials.gov/study/NCT03086213'),\n",
       " ('NCT00750269', 'https://clinicaltrials.gov/study/NCT00750269'),\n",
       " ('NCT00323869', 'https://clinicaltrials.gov/study/NCT00323869'),\n",
       " ('NCT00280735', 'https://clinicaltrials.gov/study/NCT00280735'),\n",
       " ('NCT02766335', 'https://clinicaltrials.gov/study/NCT02766335'),\n",
       " ('NCT01891669', 'https://clinicaltrials.gov/study/NCT01891669')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studies[1503:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_stata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/srikur/Desktop/medicine/exploration.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/srikur/Desktop/medicine/exploration.ipynb#W5sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39m# Save to stata .dta file\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/srikur/Desktop/medicine/exploration.ipynb#W5sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(studies_dc)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/srikur/Desktop/medicine/exploration.ipynb#W5sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m studies_dc\u001b[39m.\u001b[39;49mto_stata(\u001b[39m'\u001b[39m\u001b[39mstudies_scraped_tables_part2.dta\u001b[39m\u001b[39m'\u001b[39m, write_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, version\u001b[39m=\u001b[39m\u001b[39m118\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_stata'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "# import selenium exceptions\n",
    "from selenium.common.exceptions import *\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "ctg_studies = pd.read_csv('lung_cancer_studies_zipcodes_v2.csv')\n",
    "# Zip together 'NCT Number' and \"Study URL\"\n",
    "studies = list(zip(ctg_studies['NCT Number'], ctg_studies['Study URL']))\n",
    "\n",
    "options = Options()\n",
    "# options.add_argument('--headless')\n",
    "options.add_argument('--window-size=1920x1080')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "unscraped_links = []\n",
    "df = pd.DataFrame(columns=['NCT Number', 'Study URL', 'Table'])\n",
    "\n",
    "@dataclass\n",
    "class Study:\n",
    "    nct: str\n",
    "    link: str\n",
    "    table: str\n",
    "\n",
    "studies_dc = []\n",
    "def remove_text_between_tags(table_str: str):\n",
    "    \"\"\"\n",
    "    Removes all of the text in between a < and > for each tag, except for the tag type\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove all of the text in between a < and > for each tag, except for the tag type\n",
    "    new_table = ''\n",
    "    index = 0\n",
    "    while index < len(table_str):\n",
    "        if table_str[index] == '<':\n",
    "            new_table += table_str[index]\n",
    "            index += 1\n",
    "            # add characters until the next space is found\n",
    "            while (table_str[index] != ' ') and (table_str[index] != '>'):\n",
    "                new_table += table_str[index]\n",
    "                index += 1\n",
    "            while table_str[index] != '>':\n",
    "                index += 1\n",
    "        else:\n",
    "            new_table += table_str[index]\n",
    "        index += 1\n",
    "    \n",
    "    # Remove all \\n and spaces from string\n",
    "    new_table = new_table.replace('\\n', '')\n",
    "    new_table = new_table.replace(' ', '')\n",
    "    new_table = new_table.replace('<!--', '')\n",
    "    return new_table\n",
    "\n",
    "for nct, link in studies:\n",
    "    # 1. Use Selenium to open the link\n",
    "    # 2. Click on the \"Results Posted\" tab\n",
    "    # 3. Click on the \"Expand all\" button with the attribute data-ga-category=\"Baseline Characteristics\"\n",
    "    # 4. Extract the first instance of a <table> tag that is a child of a <ctg-sticky-container> tag\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        # Wait until the \"Results Posted\" tab is clickable\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            lambda driver: driver.find_element(By.XPATH, \"//*[contains(text(), 'Results Posted')]\").is_displayed()\n",
    "        )\n",
    "        driver.find_element(By.XPATH, \"//*[contains(text(), 'Results Posted')]\").click()\n",
    "        # Wait until the \"Expand all\" button is clickable. Use XPATH to find the button by its data-ga-category attribute\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            lambda driver: driver.find_element(By.XPATH, \"//button[@data-ga-action='Baseline Characteristics']\")\n",
    "        )\n",
    "        driver.find_element(By.XPATH, \"//button[@data-ga-action='Baseline Characteristics']\").click()\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        table = soup.select_one('ctg-baseline-characteristics').select_one('table').prettify()\n",
    "        if table:\n",
    "            # Store in a dataframe with columns \"NCT Number\", \"Study URL\", and \"Table\"\n",
    "            # First store in dataclass\n",
    "            # table = remove_text_between_tags(table)\n",
    "            study = Study(nct, link, table)\n",
    "            studies_dc.append(study)\n",
    "            # write to tsv\n",
    "            # with open('studies_scraped_tables.tsv', 'a') as f:\n",
    "            #     f.write(f'{study.nct}\\t{study.link}\\t{study.table}\\n')\n",
    "        else:\n",
    "            print('No table found for', link)\n",
    "            unscraped_links.append(link)\n",
    "            with open('unscraped_ncts.txt', 'a') as f:\n",
    "                f.write(nct + '\\n')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        df = pd.DataFrame(studies_dc)\n",
    "        studies_dc.to_stata('studies_scraped_tables_error.dta', write_index=False, version=118)\n",
    "        driver.close()\n",
    "\n",
    "# Save to stata .dta file\n",
    "df = pd.DataFrame(studies_dc)\n",
    "studies_dc.to_stata('studies_scraped_tables.dta', write_index=False, version=118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_stata('studies_scraped_tables_part2.dta', write_index=False, version=118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(studies_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(studies_dc).to_stata('studies_scraped_tables_part1.dta', write_index=False, version=118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine the two .dta files\n",
    "part1 = pd.read_stata('studies_scraped_tables_part1.dta')\n",
    "part2 = pd.read_stata('studies_scraped_tables_part2.dta')\n",
    "\n",
    "combined = pd.concat([part1, part2], ignore_index=True)\n",
    "\n",
    "#save\n",
    "combined.to_stata('studies_scraped_tables.dta', write_index=False, version=118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.read_stata('studies_scraped_tables.dta')\n",
    "ctg_studies = pd.read_excel('lung_cancer_studies_zipcodes_v2.xlsx')\n",
    "\n",
    "ctg_studies['NCT Number'] = ctg_studies['NCT Number'].astype(str)\n",
    "# make original_studies['nct'] strings\n",
    "data['nct'] = data['nct'].astype(str)\n",
    "\n",
    "# list of ctg-studies NCT Number\n",
    "ncts = ctg_studies['NCT Number'].tolist()\n",
    "\n",
    "# filter data to only include ncts in ncts list\n",
    "data = data[data['nct'].isin(ncts)]\n",
    "\n",
    "# sort by nct, ascending\n",
    "data = data.sort_values(by=['nct'])\n",
    "\n",
    "data = data[data['nct'] == 'NCT00300495']\n",
    "\n",
    "# Load the HTML template\n",
    "with open('template.html', 'r') as file:\n",
    "    template_content = file.read()\n",
    "template = Template(template_content)\n",
    "\n",
    "# Create a list of tables as (identifier, HTML_table) pairs\n",
    "tables = [(row['nct'], row['table']) for _, row in data.iterrows()]\n",
    "\n",
    "# Render the HTML\n",
    "html_output = template.render(tables=tables)\n",
    "\n",
    "# Save the HTML to a file\n",
    "with open('output_NCT00300495.html', 'w') as output_file:\n",
    "    output_file.write(html_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct</th>\n",
       "      <th>link</th>\n",
       "      <th>table</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00730925</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00730925</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT02448225</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT02448225</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00480025</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00480025</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00216125</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00216125</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00356525</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00356525</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>NCT00750269</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00750269</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>NCT00323869</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00323869</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>NCT00280735</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00280735</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>NCT02766335</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT02766335</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>NCT01891669</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT01891669</td>\n",
       "      <td>&lt;table _ngcontent-ng-c4179008994=\"\" style=\"wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              nct                                          link  \\\n",
       "0     NCT00730925  https://clinicaltrials.gov/study/NCT00730925   \n",
       "1     NCT02448225  https://clinicaltrials.gov/study/NCT02448225   \n",
       "2     NCT00480025  https://clinicaltrials.gov/study/NCT00480025   \n",
       "3     NCT00216125  https://clinicaltrials.gov/study/NCT00216125   \n",
       "4     NCT00356525  https://clinicaltrials.gov/study/NCT00356525   \n",
       "...           ...                                           ...   \n",
       "1626  NCT00750269  https://clinicaltrials.gov/study/NCT00750269   \n",
       "1627  NCT00323869  https://clinicaltrials.gov/study/NCT00323869   \n",
       "1628  NCT00280735  https://clinicaltrials.gov/study/NCT00280735   \n",
       "1629  NCT02766335  https://clinicaltrials.gov/study/NCT02766335   \n",
       "1630  NCT01891669  https://clinicaltrials.gov/study/NCT01891669   \n",
       "\n",
       "                                                  table  \n",
       "0     <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "1     <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "2     <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "3     <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "4     <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "...                                                 ...  \n",
       "1626  <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "1627  <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "1628  <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "1629  <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "1630  <table _ngcontent-ng-c4179008994=\"\" style=\"wid...  \n",
       "\n",
       "[1631 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_stata('studies_scraped_tables.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCTs to scrape: 0\n"
     ]
    }
   ],
   "source": [
    "original_studies = pd.read_stata('studies_scraped_tables_original.dta')\n",
    "ctg_studies = pd.read_excel('lung_cancer_studies_zipcodes_v2.xlsx')\n",
    "# make NCT Number strings\n",
    "ctg_studies['NCT Number'] = ctg_studies['NCT Number'].astype(str)\n",
    "# make original_studies['nct'] strings\n",
    "original_studies['nct'] = original_studies['nct'].astype(str)\n",
    "ctg_studies = ctg_studies[~ctg_studies['NCT Number'].isin(original_studies['nct'])]\n",
    "print(f\"NCTs to scrape: {len(ctg_studies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NCT00003492\n",
       "1       NCT00003508\n",
       "2       NCT00003726\n",
       "3       NCT00003869\n",
       "4       NCT00003901\n",
       "           ...     \n",
       "1254    NCT04940221\n",
       "1255    NCT04971187\n",
       "1256    NCT05030454\n",
       "1257    NCT05091528\n",
       "1258    NCT05553808\n",
       "Name: NCT Number, Length: 1259, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg_studies['NCT Number'].as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "\n",
    "@dataclass\n",
    "class StudyDetails:\n",
    "    nct: str\n",
    "    total_participants: int\n",
    "    num_female: int\n",
    "    num_male: int\n",
    "\n",
    "studies = pd.read_stata('studies_scraped_tables.dta')\n",
    "ctg_studies = pd.read_excel('lung_cancer_studies_zipcodes_v2.xlsx')\n",
    "# studies that are alos in ctg_studies\n",
    "studies = studies[studies['nct'].isin(ctg_studies['NCT Number'])]\n",
    "studies = studies.sort_values(by=['nct'])\n",
    "\n",
    "def modify_table_strings(table: str) -> str:\n",
    "    table = table.replace('<!-- -->', ' ')\n",
    "    table = table.replace('\\n   ', ' ')\n",
    "    table = table.replace('\\n', ' ')\n",
    "    return table\n",
    "\n",
    "# apply modify_table_strings to each row in studies['table']\n",
    "studies['table'] = studies['table'].apply(modify_table_strings)\n",
    "# Drop \"Total Number\", \"Female\", and \"Male\" from ctg_studies\n",
    "ctg_studies = ctg_studies[['NCT Number', 'Study Title', 'Study URL', 'Study Status',\n",
    "       'Study Results', 'Conditions', 'Interventions', 'Surgery?', 'Drug?',\n",
    "       'Behavioural?', 'Observational?', 'Phases', 'Funder Type', 'Study Type',\n",
    "       'Results First Posted', 'Locations', 'Zipcodes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sex_breakdown(row):\n",
    "    # Iterate through each tag in the first element of soup\n",
    "    # first tag in soup.children\n",
    "    nct = row[0]\n",
    "    table = row[1]\n",
    "    num_female, num_male, total_participants = -1, -1, -1\n",
    "    try:\n",
    "        soup = BeautifulSoup(table, 'html.parser')\n",
    "        soup_table = soup.select_one('table')\n",
    "        \n",
    "        # get the columns in the soup_table\n",
    "        cols = soup_table.find_all('th')\n",
    "        # check the .text of the cols for \"Total\", case insensitive\n",
    "        total_col = None\n",
    "        for idx, col in enumerate(cols):\n",
    "            if \"Total\" in col.text or \"total\" in col.text:\n",
    "                total_col = idx\n",
    "                break\n",
    "\n",
    "        # Find the element that has the text \"Age\" in it.\n",
    "        # Then find the root parent\n",
    "        tds = soup_table.find_all('td')\n",
    "        relevant_tbody = \"\"\n",
    "        for td in tds:\n",
    "            if ('Sex' in td.text) or (\"Gender\" in td.text):\n",
    "                relevant_tbody = td.parent.find_next(\"tbody\")      \n",
    "        if relevant_tbody == \"\": return (nct, -1, -1, -1)      \n",
    "\n",
    "        sex_soup = BeautifulSoup(str(relevant_tbody), 'html.parser')\n",
    "\n",
    "        trs = sex_soup.find_all('tr')\n",
    "        if len(cols) == 2:\n",
    "            # Continue as normal\n",
    "            for tr in trs:\n",
    "                tds = tr.find_all('td')\n",
    "                if \"Female\" in tds[0].text:\n",
    "                    if \"%\" in tds[-1].text:\n",
    "                        # extract the first digit using regex\n",
    "                        num_female = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    else: num_female = ''.join(filter(str.isdigit, tds[-1].text))\n",
    "                    if num_female == \"\": num_female = -1\n",
    "                    else: num_female = int(num_female)\n",
    "                elif \"Male\" in tds[0].text:\n",
    "                    if \"%\" in tds[-1].text:\n",
    "                        # extract the first digit using regex\n",
    "                        num_male = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    else: num_male = ''.join(filter(str.isdigit, tds[-1].text))\n",
    "                    if num_male == \"\": num_male = -1\n",
    "                    else: num_male = int(num_male)\n",
    "                elif \"Number Analyzed\" in tds[0].text:\n",
    "                    total_participants = ''.join(filter(str.isdigit, tds[-1].text))\n",
    "                    if total_participants == \"\": total_participants = -1\n",
    "                    else: total_participants = int(total_participants)\n",
    "        elif len(cols) == 3 and total_col is not None:\n",
    "            # Use total col\n",
    "            print(\"col == 3 and total_col is not None: \", nct)\n",
    "            pass\n",
    "        elif len(cols) == 3 and total_col is None:\n",
    "            # combine the two columns\n",
    "            print(\"col == 3 and total_col is None: \", nct)\n",
    "            pass\n",
    "        elif len(cols) > 3 and total_col is not None:\n",
    "            # use the total column\n",
    "            # For each tr in trs, get the td at the index of total_col\n",
    "            for tr in trs:\n",
    "                tds = tr.find_all('td')\n",
    "                if \"Female\" in tds[0].text:\n",
    "                    if \"%\" in tds[total_col].text:\n",
    "                        # extract the first digit using regex\n",
    "                        num_female = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    else: num_female = ''.join(filter(str.isdigit, tds[total_col].text))\n",
    "                    if num_female == \"\": num_female = -1\n",
    "                    else: num_female = int(num_female)\n",
    "                elif \"Male\" in tds[0].text:\n",
    "                    if \"%\" in tds[total_col].text:\n",
    "                        # extract the first digit using regex\n",
    "                        num_male = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    else: num_male = ''.join(filter(str.isdigit, tds[total_col].text))\n",
    "                    if num_male == \"\": num_male = -1\n",
    "                    else: num_male = int(num_male)\n",
    "                elif \"Number Analyzed\" in tds[0].text:\n",
    "                    total_participants = ''.join(filter(str.isdigit, tds[total_col].text))\n",
    "                    if total_participants == \"\": total_participants = -1\n",
    "                    else: total_participants = int(total_participants)\n",
    "        elif len(cols) > 3 and total_col is None:\n",
    "            # need to manually check\n",
    "            print(\"col > 3: Gender Breakdown manually check: \", nct)\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(\"Sex Exception: \", nct)\n",
    "        return (nct, -1, -1, -1)\n",
    "    return (nct, num_female, num_male, total_participants)\n",
    "\n",
    "def get_age_breakdown(row):\n",
    "    nct = row[0]\n",
    "    table = row[1]\n",
    "    mean, median = -1, -1\n",
    "    mean_flag, median_flag = False, False\n",
    "\n",
    "    if \"Age, Continuous\" not in table: return (nct, -1, -1)\n",
    "    try:\n",
    "        soup = BeautifulSoup(table, 'html.parser')\n",
    "        soup_table = soup.select_one('table')\n",
    "        # get the columns in the soup_table\n",
    "        cols = soup_table.find_all('th')\n",
    "        # check the .text of the cols for \"Total\", case insensitive\n",
    "        total_col = None\n",
    "        for idx, col in enumerate(cols):\n",
    "            if \"Total\" in col.text or \"total\" in col.text:\n",
    "                total_col = idx\n",
    "                break\n",
    "\n",
    "        # Find the element that has the text \"Age\" in it.\n",
    "        # Then find the root parent\n",
    "        tds = soup_table.find_all('td')\n",
    "        relevant_tbody = \"\"\n",
    "        for td in tds:\n",
    "            if ('Age, Continuous' in td.text):\n",
    "                if (\"Mean\") in td.text: mean_flag = True\n",
    "                if (\"Median\") in td.text: median_flag = True\n",
    "                relevant_tbody = td.parent.find_next(\"tbody\")  \n",
    "        if relevant_tbody == \"\": \n",
    "            print(f\"Could not find relevant_tbody for {nct}\")\n",
    "            return (nct, -1, -1, -1)      \n",
    "\n",
    "        age_soup = BeautifulSoup(str(relevant_tbody), 'html.parser')\n",
    "        trs = age_soup.find_all('tr')\n",
    "        tr =  trs[-1]\n",
    "        \n",
    "        if len(cols) == 2:\n",
    "            # Continue as normal\n",
    "            tds = tr.find_all('td')\n",
    "\n",
    "            if mean_flag: mean = float(re.match(r'\\s*([0-9]+(?:\\.\\d+)?)\\s*', tds[-1].text).group(1))\n",
    "            if median_flag: median = float(re.match(r'\\s*([0-9]+(?:\\.\\d+)?)\\s*', tds[-1].text).group(1))\n",
    "        elif len(cols) == 3 and total_col is not None:\n",
    "            # Use total col\n",
    "            print(\"col == 3 and total_col is not None: \", nct)\n",
    "            pass\n",
    "        elif len(cols) == 3 and total_col is None:\n",
    "            # combine the two columns\n",
    "            print(\"col == 3 and total_col is None: \", nct)\n",
    "            pass\n",
    "        elif len(cols) > 3 and total_col is not None:\n",
    "            tds = tr.find_all('td')\n",
    "            # print(nct)\n",
    "            if mean_flag: mean = float(re.match(r'\\s*([0-9]+(?:\\.\\d+)?)\\s*', tds[total_col].text).group(1))\n",
    "            # print(tds[total_col].text)\n",
    "            if median_flag: median = float(re.match(r'\\s*([0-9]+(?:\\.\\d+)?)\\s*', tds[total_col].text).group(1))\n",
    "        elif len(cols) > 3 and total_col is None:\n",
    "            # need to manually check\n",
    "            print(\"col > 3: Gender Breakdown manually check: \", nct)\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(\"Age Exception: \", nct)\n",
    "        return (nct, -1, -1)\n",
    "    return (nct, mean, median)\n",
    "\n",
    "@dataclass\n",
    "class RaceEthnicity:\n",
    "    american_indian: int\n",
    "    asian: int\n",
    "    native_hawaiian: int\n",
    "    black: int\n",
    "    white: int\n",
    "    mixed: int\n",
    "    race_unknown: int\n",
    "    hispanic: int\n",
    "    not_hispanic: int\n",
    "    ethnicity_unknown: int\n",
    "    race_ethnicity_flag: int\n",
    "\n",
    "def get_race_breakdown(row):\n",
    "    # Flag if \"Race/Ethnicity\" is in the table\n",
    "    race_ethnicity_flag = False\n",
    "    nct = row[0]\n",
    "    table = row[1]\n",
    "\n",
    "    # race categories\n",
    "    american_indian, asian, native_hawaiian, black, white, mixed, race_unknown = -1, -1, -1, -1, -1, -1, -1\n",
    "\n",
    "    # nih ethnicity\n",
    "    hispanic, not_hispanic, ethnicity_unknown = -1, -1, -1\n",
    "\n",
    "    if \"Race\" in table or \"Ethnicity\" in table: race_ethnicity_flag = True\n",
    "    else: return (nct, RaceEthnicity(-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1))\n",
    "\n",
    "    try:\n",
    "        soup = BeautifulSoup(table, 'html.parser')\n",
    "        soup_table = soup.select_one('table')\n",
    "        # get the columns in the soup_table\n",
    "        cols = soup_table.find_all('th')\n",
    "        # check the .text of the cols for \"Total\", case insensitive\n",
    "        total_col = None\n",
    "        for idx, col in enumerate(cols):\n",
    "            if \"Total\" in col.text or \"total\" in col.text:\n",
    "                total_col = idx\n",
    "                break\n",
    "\n",
    "        tds = soup_table.find_all('td')\n",
    "        ethnicity_tbody, race_tbody = \"\", \"\"\n",
    "        for td in tds:\n",
    "            if ('Ethnicity (NIH/OMB)' in td.text):\n",
    "                ethnicity_tbody = td.parent.find_next(\"tbody\")  \n",
    "            if (\"Race (NIH/OMB)\" in td.text):\n",
    "                race_tbody = td.parent.find_next(\"tbody\")\n",
    "\n",
    "        # Ethnicity\n",
    "        ethnicity_soup = BeautifulSoup(str(ethnicity_tbody), 'html.parser')\n",
    "        trs = ethnicity_soup.find_all('tr')\n",
    "        if len(cols) == 2:\n",
    "            for tr in trs:\n",
    "                tds = tr.find_all('td')\n",
    "                if \"Not Hispanic or Latino\" in tds[0].text:\n",
    "                    not_hispanic = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    # print(\"Not Hispanic or Latino: \", not_hispanic)\n",
    "                elif \"Hispanic or Latino\" in tds[0].text:\n",
    "                    hispanic = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    # print(\"Hispanic or Latino: \", hispanic)\n",
    "                elif \"Unknown or Not Reported\" in tds[0].text:\n",
    "                    ethnicity_unknown = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    # print(\"Unknown ethnicity:\", ethnicity_unknown)\n",
    "        else:\n",
    "            for tr in trs:\n",
    "                tds = tr.find_all('td')\n",
    "                if \"Not Hispanic or Latino\" in tds[0].text:\n",
    "                    not_hispanic = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    # print(\"Not Hispanic or Latino: \", not_hispanic)\n",
    "                elif \"Hispanic or Latino\" in tds[0].text:\n",
    "                    hispanic = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    # print(\"Hispanic or Latino: \", hispanic)\n",
    "                elif \"Unknown or Not Reported\" in tds[0].text:\n",
    "                    ethnicity_unknown = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    # print(\"Unknown ethnicity:\", ethnicity_unknown)\n",
    "\n",
    "        # Race\n",
    "        race_soup = BeautifulSoup(str(race_tbody), 'html.parser')\n",
    "        trs = race_soup.find_all('tr')\n",
    "        if len(cols) == 2:\n",
    "            for tr in trs:\n",
    "                tds = tr.find_all('td')\n",
    "                if \"American Indian or Alaska Native\" in tds[0].text:\n",
    "                    american_indian = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    print(\"American Indian or Alaska Native:\", american_indian)\n",
    "                elif \"Asian\" in tds[0].text:\n",
    "                    asian = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    # print(\"Asian:\", asian)\n",
    "                elif \"Native Hawaiian or Other Pacific Islander\" in tds[0].text:\n",
    "                    native_hawaiian = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    # print(\"Native Hawaiian or Other Pacific Islander:\", native_hawaiian)\n",
    "                elif \"Black or African American\" in tds[0].text:\n",
    "                    black = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    # print(\"Black or African American:\", black)\n",
    "                elif \"White\" in tds[0].text:\n",
    "                    white = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    # print(\"White:\", white)\n",
    "                elif \"Unknown or Not Reported\" in tds[0].text:\n",
    "                    race_unknown = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    # print(\"Race unknown:\", race_unknown)\n",
    "                elif \"More than one race\" in tds[0].text:\n",
    "                    mixed = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[-1].text).group(2))\n",
    "                    # print(\"Mixed:\", mixed)\n",
    "        else:\n",
    "            for tr in trs:\n",
    "                tds = tr.find_all('td')\n",
    "                if \"American Indian or Alaska Native\" in tds[0].text:\n",
    "                    american_indian = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    print(\"American Indian or Alaska Native:\", american_indian)\n",
    "                elif \"Asian\" in tds[0].text:\n",
    "                    asian = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    # print(\"Asian:\", asian)\n",
    "                elif \"Native Hawaiian or Other Pacific Islander\" in tds[0].text:\n",
    "                    native_hawaiian = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    # print(\"Native Hawaiian or Other Pacific Islander:\", native_hawaiian)\n",
    "                elif \"Black or African American\" in tds[0].text:\n",
    "                    black = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    # print(\"Black or African American:\", black)\n",
    "                elif \"White\" in tds[0].text:\n",
    "                    white = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    # print(\"White:\", white)\n",
    "                elif \"Unknown or Not Reported\" in tds[0].text:\n",
    "                    race_unknown = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    # print(\"Race unknown:\", race_unknown)\n",
    "                elif \"More than one race\" in tds[0].text:\n",
    "                    mixed = int(re.match(r'\\s*([^\\d]+)\\s*(\\d+)', tds[total_col].text).group(2))\n",
    "                    # print(\"Mixed:\", mixed)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Race/Ethnicity Exception: {nct}\")\n",
    "        return (nct, RaceEthnicity(-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1))\n",
    "\n",
    "    ret_object = RaceEthnicity(american_indian=american_indian, \\\n",
    "                            asian=asian,\\\n",
    "                            native_hawaiian=native_hawaiian,\\\n",
    "                            black=black,\\\n",
    "                            white=white,\\\n",
    "                            race_unknown=race_unknown,\\\n",
    "                            mixed=mixed,\\\n",
    "                            hispanic=hispanic,\\\n",
    "                            not_hispanic=not_hispanic,\\\n",
    "                            ethnicity_unknown=ethnicity_unknown,\\\n",
    "                            race_ethnicity_flag=race_ethnicity_flag)\n",
    "    \n",
    "    return (nct, ret_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex Exception:  NCT00300495\n",
      "Sex Exception:  NCT02712905\n",
      "Sex Exception:  NCT04314284\n",
      "Age Exception:  NCT00137839\n",
      "Age Exception:  NCT00252382\n",
      "Age Exception:  NCT00373425\n",
      "Age Exception:  NCT00492206\n",
      "Age Exception:  NCT00531284\n",
      "Age Exception:  NCT00550654\n",
      "Age Exception:  NCT00840749\n",
      "Age Exception:  NCT01021215\n",
      "Age Exception:  NCT01177397\n",
      "Age Exception:  NCT01523587\n",
      "Age Exception:  NCT01524783\n",
      "Age Exception:  NCT01587703\n",
      "Age Exception:  NCT01970865\n",
      "Age Exception:  NCT02027428\n",
      "Age Exception:  NCT02034123\n",
      "Age Exception:  NCT02213133\n",
      "Age Exception:  NCT02222922\n",
      "Age Exception:  NCT02289456\n",
      "Age Exception:  NCT02289690\n",
      "Age Exception:  NCT02296125\n",
      "Age Exception:  NCT02336451\n",
      "Age Exception:  NCT02393248\n",
      "Age Exception:  NCT02411448\n",
      "Age Exception:  NCT02423343\n",
      "Age Exception:  NCT02451930\n",
      "Age Exception:  NCT02452554\n",
      "Age Exception:  NCT02546986\n",
      "Age Exception:  NCT02642042\n",
      "Age Exception:  NCT02695290\n",
      "Age Exception:  NCT02701400\n",
      "Age Exception:  NCT02702921\n",
      "Age Exception:  NCT02711137\n",
      "Age Exception:  NCT02712905\n",
      "Age Exception:  NCT02751879\n",
      "Age Exception:  NCT02763579\n",
      "Age Exception:  NCT03007953\n",
      "Age Exception:  NCT03603652\n",
      "Age Exception:  NCT03775486\n",
      "Age Exception:  NCT04161157\n",
      "Age Exception:  NCT04225026\n",
      "Age Exception:  NCT04314284\n",
      "Age Exception:  NCT04424641\n",
      "Age Exception:  NCT04644315\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 3\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 6\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 11\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 5\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 4\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 9\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 29\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 4\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 4\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "Race/Ethnicity Exception: NCT01672294\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 5\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 26\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 5\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 14\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 4\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 4\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 5\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "Race/Ethnicity Exception: NCT02410382\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 40\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 5\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 6\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 5\n",
      "American Indian or Alaska Native: 8\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 7\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 2\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "Race/Ethnicity Exception: NCT03455556\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 10\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 45\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 1\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 11\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n",
      "American Indian or Alaska Native: 0\n"
     ]
    }
   ],
   "source": [
    "study_details = []\n",
    "ncts_tables = list(zip(studies['nct'], studies['table']))\n",
    "\n",
    "gender_breakdowns = [get_sex_breakdown(row) for row in ncts_tables]\n",
    "age_breakdowns = [get_age_breakdown(row) for row in ncts_tables]\n",
    "race_ethnicity_breakdowns = [get_race_breakdown(row) for row in ncts_tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NCT04940221', '64.1', -1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_age_breakdown((\"NCT04940221\", studies[studies['nct'] == \"NCT04940221\"]['table'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_breakdowns_df = pd.DataFrame(gender_breakdowns, columns=[\"NCT Number\", \"Female\", \"Male\", \"Total Number\"])\n",
    "age_breakdowns_df = pd.DataFrame(age_breakdowns, columns=[\"NCT Number\", \"Mean\", \"Median\"])\n",
    "race_ethnicity_breakdowns_flattened = [(nct, data.american_indian, data.asian, data.native_hawaiian, \n",
    "                              data.black, data.white, data.mixed, data.race_unknown, data.hispanic, data.not_hispanic, \n",
    "                              data.ethnicity_unknown, data.race_ethnicity_flag) for nct, data in race_ethnicity_breakdowns]\n",
    "race_ethnicity_breakdowns_df = pd.DataFrame(race_ethnicity_breakdowns_flattened, columns=[\"NCT Number\", \"Native American\", \"Asian\", \"Pacific\", \n",
    "                                                                                \"Black\", \"White\", \"Mixed\", \"Unknown Race\", \"Hispanic\",\n",
    "                                                                                \"Non-His\", \"Unknown Ethnicity\", \"Race/Ethnicity Flag\"])\n",
    "new_ctg_studies = ctg_studies.merge(gender_breakdowns_df, on=\"NCT Number\", how=\"left\")\n",
    "new_ctg_studies = new_ctg_studies.merge(age_breakdowns_df, on=\"NCT Number\", how=\"left\")\n",
    "new_ctg_studies = new_ctg_studies.merge(race_ethnicity_breakdowns_df, on=\"NCT Number\", how=\"left\")\n",
    "\n",
    "# new_ctg_studies.to_excel('lung_cancer_studies_scraped.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dates = pd.read_csv(\"ctg-studies (6).csv\")\n",
    "# merge with new_ctg_studies on NCT Number\n",
    "new_ctg_studies = new_ctg_studies.merge(start_dates, on=\"NCT Number\", how=\"left\")\n",
    "new_ctg_studies.to_excel('lung_cancer_studies_scraped.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCT Number</th>\n",
       "      <th>Study Title</th>\n",
       "      <th>Study URL</th>\n",
       "      <th>Study Status</th>\n",
       "      <th>Study Results</th>\n",
       "      <th>Conditions</th>\n",
       "      <th>Interventions</th>\n",
       "      <th>Surgery?</th>\n",
       "      <th>Drug?</th>\n",
       "      <th>Behavioural?</th>\n",
       "      <th>...</th>\n",
       "      <th>Pacific</th>\n",
       "      <th>Black</th>\n",
       "      <th>White</th>\n",
       "      <th>Mixed</th>\n",
       "      <th>Unknown Race</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Non-His</th>\n",
       "      <th>Unknown Ethnicity</th>\n",
       "      <th>Race/Ethnicity Flag</th>\n",
       "      <th>Start Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00003901</td>\n",
       "      <td>Prognostic Study of Metastases in Patients Wit...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00003901</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>YES</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>OTHER: immunohistochemistry staining method|PR...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>1999-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NCT00004547</td>\n",
       "      <td>Treatment of Peritoneal Cancer With Surgery, P...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00004547</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>YES</td>\n",
       "      <td>Abdominal Neoplasm|Colonic Neoplasm|Mesothelio...</td>\n",
       "      <td>PROCEDURE: Surgery|PROCEDURE: Continuous hyper...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>2000-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NCT00043108</td>\n",
       "      <td>Combination Chemotherapy, Surgery, and Radiati...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00043108</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>YES</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>DRUG: carboplatin|DRUG: paclitaxel|PROCEDURE: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>2002-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NCT00045162</td>\n",
       "      <td>S0124: Cisplatin Combined With Irinotecan or E...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00045162</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>YES</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>DRUG: cisplatin|DRUG: etoposide|DRUG: irinotec...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>577</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "      <td>2002-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NCT00073008</td>\n",
       "      <td>A Study Of Oral GW572016 In Advanced Or Metast...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT00073008</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>YES</td>\n",
       "      <td>Lung Cancer, Non-Small Cell</td>\n",
       "      <td>DRUG: GW572016 (lapatinib)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>2003-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>NCT04422210</td>\n",
       "      <td>A Study Evaluating The Safety, Tolerability, P...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT04422210</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>YES</td>\n",
       "      <td>Small Cell Lung Cancer</td>\n",
       "      <td>DRUG: Venetoclax|DRUG: Atezolizumab|DRUG: Carb...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>9/22/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>NCT04491084</td>\n",
       "      <td>FLT3 Ligand, CD40 Agonist Antibody, and Stereo...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT04491084</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>YES</td>\n",
       "      <td>Non Small Cell Lung Cancer|Lung Cancer</td>\n",
       "      <td>DRUG: FLT3 Ligand (CDX-301)|BIOLOGICAL: anti-C...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>1/1/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>NCT04581824</td>\n",
       "      <td>Efficacy Comparison of Dostarlimab Plus Chemot...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT04581824</td>\n",
       "      <td>ACTIVE_NOT_RECRUITING</td>\n",
       "      <td>YES</td>\n",
       "      <td>Lung Cancer, Non-Small Cell</td>\n",
       "      <td>DRUG: Dostarlimab|DRUG: Pembrolizumab|DRUG: Ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>11/19/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>NCT04644315</td>\n",
       "      <td>A Home-Based Approach Study to Evaluate the Ef...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT04644315</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>YES</td>\n",
       "      <td>Neoplasms|Colorectal Neoplasms|Melanoma|Pancre...</td>\n",
       "      <td>DRUG: Alectinib</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>5/24/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>NCT05553808</td>\n",
       "      <td>Platform Trial of Novel Regimens Versus Standa...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT05553808</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>YES</td>\n",
       "      <td>Neoplasms</td>\n",
       "      <td>DRUG: Docetaxel|DRUG: Feladilimab</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1/24/19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NCT Number                                        Study Title  \\\n",
       "4     NCT00003901  Prognostic Study of Metastases in Patients Wit...   \n",
       "5     NCT00004547  Treatment of Peritoneal Cancer With Surgery, P...   \n",
       "9     NCT00043108  Combination Chemotherapy, Surgery, and Radiati...   \n",
       "10    NCT00045162  S0124: Cisplatin Combined With Irinotecan or E...   \n",
       "28    NCT00073008  A Study Of Oral GW572016 In Advanced Or Metast...   \n",
       "...           ...                                                ...   \n",
       "1237  NCT04422210  A Study Evaluating The Safety, Tolerability, P...   \n",
       "1242  NCT04491084  FLT3 Ligand, CD40 Agonist Antibody, and Stereo...   \n",
       "1245  NCT04581824  Efficacy Comparison of Dostarlimab Plus Chemot...   \n",
       "1251  NCT04644315  A Home-Based Approach Study to Evaluate the Ef...   \n",
       "1258  NCT05553808  Platform Trial of Novel Regimens Versus Standa...   \n",
       "\n",
       "                                         Study URL           Study Status  \\\n",
       "4     https://clinicaltrials.gov/study/NCT00003901              COMPLETED   \n",
       "5     https://clinicaltrials.gov/study/NCT00004547              COMPLETED   \n",
       "9     https://clinicaltrials.gov/study/NCT00043108              COMPLETED   \n",
       "10    https://clinicaltrials.gov/study/NCT00045162              COMPLETED   \n",
       "28    https://clinicaltrials.gov/study/NCT00073008             TERMINATED   \n",
       "...                                            ...                    ...   \n",
       "1237  https://clinicaltrials.gov/study/NCT04422210             TERMINATED   \n",
       "1242  https://clinicaltrials.gov/study/NCT04491084             TERMINATED   \n",
       "1245  https://clinicaltrials.gov/study/NCT04581824  ACTIVE_NOT_RECRUITING   \n",
       "1251  https://clinicaltrials.gov/study/NCT04644315             TERMINATED   \n",
       "1258  https://clinicaltrials.gov/study/NCT05553808              COMPLETED   \n",
       "\n",
       "     Study Results                                         Conditions  \\\n",
       "4              YES                                        Lung Cancer   \n",
       "5              YES  Abdominal Neoplasm|Colonic Neoplasm|Mesothelio...   \n",
       "9              YES                                        Lung Cancer   \n",
       "10             YES                                        Lung Cancer   \n",
       "28             YES                        Lung Cancer, Non-Small Cell   \n",
       "...            ...                                                ...   \n",
       "1237           YES                             Small Cell Lung Cancer   \n",
       "1242           YES             Non Small Cell Lung Cancer|Lung Cancer   \n",
       "1245           YES                        Lung Cancer, Non-Small Cell   \n",
       "1251           YES  Neoplasms|Colorectal Neoplasms|Melanoma|Pancre...   \n",
       "1258           YES                                          Neoplasms   \n",
       "\n",
       "                                          Interventions  Surgery?  Drug?  \\\n",
       "4     OTHER: immunohistochemistry staining method|PR...         1      0   \n",
       "5     PROCEDURE: Surgery|PROCEDURE: Continuous hyper...         0      1   \n",
       "9     DRUG: carboplatin|DRUG: paclitaxel|PROCEDURE: ...         1      1   \n",
       "10    DRUG: cisplatin|DRUG: etoposide|DRUG: irinotec...         0      1   \n",
       "28                           DRUG: GW572016 (lapatinib)         0      1   \n",
       "...                                                 ...       ...    ...   \n",
       "1237  DRUG: Venetoclax|DRUG: Atezolizumab|DRUG: Carb...         0      1   \n",
       "1242  DRUG: FLT3 Ligand (CDX-301)|BIOLOGICAL: anti-C...         0      1   \n",
       "1245  DRUG: Dostarlimab|DRUG: Pembrolizumab|DRUG: Ch...         0      1   \n",
       "1251                                    DRUG: Alectinib         0      1   \n",
       "1258                  DRUG: Docetaxel|DRUG: Feladilimab         0      1   \n",
       "\n",
       "      Behavioural?  ...  Pacific Black White Mixed Unknown Race Hispanic  \\\n",
       "4                0  ...       -1    -1    -1    -1           -1       -1   \n",
       "5                0  ...       -1    -1    -1    -1           -1       -1   \n",
       "9                0  ...       -1    -1    -1    -1           -1       -1   \n",
       "10               0  ...       -1    -1    -1    -1           -1       14   \n",
       "28               0  ...       -1    -1    -1    -1           -1       -1   \n",
       "...            ...  ...      ...   ...   ...   ...          ...      ...   \n",
       "1237             0  ...       -1    -1    -1    -1           -1       -1   \n",
       "1242             0  ...       -1    -1    -1    -1           -1       -1   \n",
       "1245             0  ...       -1    -1    -1    -1           -1       -1   \n",
       "1251             0  ...       -1    -1    -1    -1           -1       -1   \n",
       "1258             0  ...       -1    -1    -1    -1           -1        2   \n",
       "\n",
       "     Non-His  Unknown Ethnicity  Race/Ethnicity Flag  Start Date  \n",
       "4         -1                 -1                 True     1999-07  \n",
       "5         -1                 -1                 True     2000-01  \n",
       "9         -1                 -1                 True     2002-07  \n",
       "10       577                 60                 True     2002-11  \n",
       "28        -1                 -1                 True     2003-11  \n",
       "...      ...                ...                  ...         ...  \n",
       "1237      -1                 -1                 True     9/22/20  \n",
       "1242      -1                 -1                 True      1/1/21  \n",
       "1245      -1                 -1                 True    11/19/20  \n",
       "1251      -1                 -1                 True     5/24/21  \n",
       "1258     102                  1                 True     1/24/19  \n",
       "\n",
       "[273 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ctg_studies[(new_ctg_studies[\"Race/Ethnicity Flag\"] == True) & (new_ctg_studies[\"White\"] == -1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
